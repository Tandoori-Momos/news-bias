{"version":3,"sources":["../../../src/tasks/WebScraper/Scrape.js"],"names":["puppeteer","launch","headless","process","argv","browser","newPage","page","on","console","log","consoleObj","text","biases","i","length","MediaListing","close","error","Scrape","mongoose","require","connect","useNewUrlParser","then","catch","err"],"mappings":";;;;;;;;;;;wFAuBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+BAE8BA,UAAUC,MAAV,CAAiB;AACnCC,sCAAWC,QAAQC,IAAR,CAAa,CAAb,CAAD,GAAoB,KAApB,GAA4B;AADH,yBAAjB,CAF9B;;AAAA;AAEcC,+BAFd;AAAA;AAAA,+BAM2BA,QAAQC,OAAR,EAN3B;;AAAA;AAMcC,4BANd;;;AAQQA,6BAAKC,EAAL,CAAQ,SAAR,EAAmB;AAAA,mCAAcC,QAAQC,GAAR,CAAYC,WAAWC,IAAX,EAAZ,CAAd;AAAA,yBAAnB;;AAEMC,8BAVd,GAUuB,CAAC,MAAD,EAAS,YAAT,EAAuB,QAAvB,EAAiC,cAAjC,EAAiD,OAAjD,EAA0D,WAA1D,CAVvB;AAYiBC,yBAZjB,GAYqB,CAZrB;;AAAA;AAAA,8BAYwBA,IAAID,OAAOE,MAZnC;AAAA;AAAA;AAAA;;AAAA;AAAA,+BAakBC,aAAaT,IAAb,EAAmBM,OAAOC,CAAP,CAAnB,CAblB;;AAAA;AAY2CA,2BAZ3C;AAAA;AAAA;;AAAA;AAAA;AAAA,+BAgBcT,QAAQY,KAAR,EAhBd;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAmBQR,gCAAQS,KAAR;;AAnBR;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,K;;oBAAeC,M;;;;;;;AAvBf;AACA;;AAEA,IAAMC,WAAWC,QAAQ,UAAR,CAAjB;AACA,IAAMrB,YAAYqB,QAAQ,WAAR,CAAlB;AACA,IAAML,eAAeK,QAAQ,gBAAR,CAArB;;AAGA;AACAD,SAASE,OAAT,CAAiB,2DAAjB,EAA8E;AAC1EC,qBAAiB;AADyD,CAA9E,EAGCC,IAHD,CAGM,YAAM;AACRf,YAAQC,GAAR,CAAY,sBAAZ;AACAS,aACKK,IADL,CACU;AAAA,eAAMf,QAAQC,GAAR,CAAY,kBAAZ,CAAN;AAAA,KADV,EAEKe,KAFL,CAEW,UAACC,GAAD;AAAA,eAASjB,QAAQS,KAAR,CAAcQ,GAAd,CAAT;AAAA,KAFX;AAGH,CARD,EASCD,KATD,CASO,UAACC,GAAD,EAAS;AACZjB,YAAQS,KAAR,CAAcQ,GAAd;AACH,CAXD","file":"Scrape.js","sourcesContent":["// LAST SCRAPPED: 14/8/2019\n// NEXT SCRAPE: 14/12/2019\n\nconst mongoose = require('mongoose');\nconst puppeteer = require('puppeteer');\nconst MediaListing = require('./MediaListing');\n\n\n// Connect to mongodb \nmongoose.connect('mongodb://admin:admin12@ds243897.mlab.com:43897/news-bias', {\n    useNewUrlParser: true\n})\n.then(() => {\n    console.log('Connected to mongodb');\n    Scrape()\n        .then(() => console.log('Scrapped website'))\n        .catch((err) => console.error(err));\n}) \n.catch((err) => {\n    console.error(err);\n});\n\n\nasync function Scrape() {\n    try {\n        const browser = await puppeteer.launch({\n            headless: (process.argv[3]) ? false : true\n        });\n\n        const page = await browser.newPage();\n        \n        page.on('console', consoleObj => console.log(consoleObj.text()))\n\n        const biases = ['Left', 'leftcenter', 'center', 'right-center', 'right', 'fake-news'];\n\n        for (let i = 0; i < biases.length; i++) {\n            await MediaListing(page, biases[i]);\n        }\n\n        await browser.close();\n\n    } catch (err) {\n        console.error(err);\n    } \n}\n"]}